#!/bin/bash

#SBATCH --partition=compute
#SBATCH --job-name=metagenome
#SBATCH --mail-type=ALL
#SBATCH --mail-user=katelane@mit.edu
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=180G
#SBATCH --time=48:00:00
#SBATCH --output=metagenome%j.log
#export OMP_NUM_THREADS=36

#Run the setup.sh script first

#Note - This script can be broken into parts in order to run on cluster if jobs must be shorter than 48hrs.

##Create conda environment
conda env create -f LANE_metagenome.yml


##Activate conda environment:
conda activate metagenome

#Define rootdir on your computing environment, this is the directory if you type `pwd` inside the directory from cloning this repo. For example, on the Poseidon HPC:
rootdir=/vortexfs1/omics/env-bio/collaboration/jahala/


##Download Data
cd ${rootdir}/data/raw_data/
for i in `cat  access_list_mg.txt`
do
fasterq-dump --split-3 --verbose -O metagenome/ $i
done
#access list is present in /tools/ directory, and in /data/raw_data/ directory. Accession list is also here: SRR10411456


##Trim Reads
cd ${rootdir}/data/raw_data/metagenome

for i in `cat ../access_list_mg.txt`
do
trimmomatic PE -threads 36 ${i}_1.fastq  ${i}_2.fastq ${i}_1.trimmed.fastq.gz ${i}_1un.trimmed.fastq.gz ${i}_2.trimmed.fastq.gz ${i}_2un.trimmed.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:40:15 MINLEN:75
done
#un is unpaired output, TruSeq3-PE.fa is present in the raw_data/metagenome/ directory and in the the /tools/ directory for reference

##Filter and Remove Diatom Reads


##Map

